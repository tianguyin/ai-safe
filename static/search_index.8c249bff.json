[{"id":1,"title":"典型架构卷积神经网络的参数恢复","content":"#\n\n\n为什么要进行参数恢复#\n\n对于典型架构卷积神经网络，我们必须要获取其cnn参数才能正常运行其权重文件，这是后续攻击的基础。\n\nclass cnn就像是一个接口，告诉框架该模型怎么去调用。\n\n\n获取CNN（模型类名）#\n\n例题 2025 软件安全赛（天津赛区）ez_sight ai部分\n这里采用这道题目，是因为这是一个已经训练好了的典型架构卷积神经网络的权重模型（我懒的自己训练一个了），本篇文章也是建立在典型架构卷积神经网络的基础上进行参数恢复\n\n当然，当时这道题目给了一个公告文档 不过我这里并不打算通过这个文档解题，这里我们通过恢复参数的方式进行解题\n\n目前我们没有任何已知信息，我们只有一个password.pt的权重文件\n\n\n\n\n\n从上方代码中我们可以看到，由于没有从报错中我们，我们可以获取模型的cnn类名 SimpleCNN\n\n> 注意如果你的cnn类名称为SimpleCNN 那你的class 一定为class SimpleCNN\n\n注意 ，典型架构卷积神经网络 的 CNN一般长下面这个样子\n\n\n\n那么，我们可以通过 构造一个无用的SimpleCNN 来尝试调用该权重文件\n\n如果成功，就可以通过该方法获取SimpleCNN的模型参数\n\n\n\n通过遍历model，来获取所有的参数\n\n这里直接附上截图，也可以自己跑一下\n\n\n\n我们可以通过Pycharm的注释看到更清楚一点\n\n\n\n\n推断数据流动路径#\n\n\n\n基于组件信息，可以按以下步骤重构 forward 逻辑：\n\n（1）卷积部分#\n\n * 典型 CNN 的卷积部分遵循 卷积 → 激活 → 池化 的顺序。\n\n * 每一层的输出通道数需与下一层的输入通道数匹配。\n   \n   self.conv1(x)：对输入进行第一次卷积操作。\n   \n   F.relu(...)：应用 ReLU 激活函数引入非线性。\n   \n   self.pool(...)：使用最大池化降维，保留主要特征。\n\n * 重复上述步骤完成第二个卷积块。\n\n（2）展平操作#\n\n * 卷积输出需要通过 view() 或 flatten() 转换为一维向量，才能输入全连接层。\n\n * 展平后的维度需与 fc1 的输入特征数一致（本例中为 32 * 8 * 8）。\n   \n   保留批次维度：x.size(0) 表示批次大小（batch size），即当前批次中有多少个样本。\n   \n   展平特征维度：-1 是一个特殊参数，表示 \"自动计算该维度的大小\"，PyTorch\n   会根据张量的总元素数和已知维度（x.size(0)）来推断这个维度的值。\n\n（3）全连接部分#\n\n * 通常包含非线性激活（如 ReLU），但最后一层分类任务一般不加激活（直接接 softmax）。\n   \n   x = F.relu(self.fc1(x)) # 第一个全连接层 + ReLU 激活 x = self.fc2(x) #\n   第二个全连接层（输出层，无激活）\n\n现在我们来看公告中的用例守则\n\n请注意公司内部AI模型的使用规范： 1.除最后一层外与池化层外其他隐藏层输出均需要通过激活函数 2.至少需要通过两次池化层\n3.注意隐藏之间输出数据格式的匹配，必要时对数据张量进行重塑 4.为保证模型准确性，输入图片应转换为灰度图\n\n3和4不在讨论范围之内\n\n1.除最后一层外与池化层外其他隐藏层输出均需要通过激活函数\n\nself.conv1(x)：对输入进行第一次卷积操作。\n\nF.relu(...)：应用 ReLU 激活函数引入非线性。\n\nself.pool(...)：使用最大池化降维，保留主要特征。\n\n完成了\n\n2.至少需要通过两次池化层\n\n重复上述步骤完成第二个卷积块。\n\n发现，两个用例都已经遵守了。\n\n通过该方式，我们可以简单的在黑盒状态下调用权重模型","routePath":"/start/class_cnn","lang":"","toc":[{"text":"为什么要进行参数恢复","id":"为什么要进行参数恢复","depth":2,"charIndex":3},{"text":"获取CNN（模型类名）","id":"获取cnn模型类名","depth":2,"charIndex":99},{"text":"**推断数据流动路径**","id":"推断数据流动路径","depth":2,"charIndex":-1},{"text":"**（1）卷积部分**","id":"1卷积部分","depth":4,"charIndex":-1},{"text":"**（2）展平操作**","id":"2展平操作","depth":4,"charIndex":-1},{"text":"**（3）全连接部分**","id":"3全连接部分","depth":4,"charIndex":-1}],"domain":"","frontmatter":{},"version":""},{"id":2,"title":"新手上路","content":"#\n\n什么是AI安全？为什么要学习AI安全？\n\n\n实话实说#\n\n对于作者来说，仅仅是为了在CTF比赛中拿分。近年来，准确来说应该是，从2024年开始，AI安全的分数比重，无论是线上还是线下，\n都在大幅度提高，各大安全厂商的研究重心，市场风向都指向了ai安全。\n\n\n什么是AI安全#\n\nAI安全（AI Security），是指确保人工智能系统在设计、训练、部署和使用全过程中的安全性、鲁棒性与可信性的一系列技术、\n策略和机制。它涵盖了防止AI系统被攻击、被误用或做出错误决策等风险。 -- From Chatgpt\n\n至少在初学阶段可以这么归类--凡是包含了大模型、人工智能、深度学习等概念的安全类知识都可以称之为AI安全\n\n比如说，ollama在某些版本中存在的 拉取模型时，未授权导致的任意文件读写，尽管看上去很像传统安全，但是由于沾了ai的边，也被归类为ai安全（\n\n\nAI安全的类别#\n\n\n1.对抗性攻击与防御（Adversarial ML）#\n\n\n2.隐私保护（Privacy in AI）#\n\n\n3.模型行为安全（Behavioral Safety）#\n\n\n4. 后门与模型篡改防御（Backdoor/Poisoning）#\n\n\n5. 大模型（LLM）安全#\n\n更详细的分类其实可以看\n\n\n\n\n#\n\n就目前来说，受限于作者水平问题，不太可能会出现质量特别高的文章 ):\n\n本文档仅适合入门者进行交流，作者也是新手\n\n如果文档有问题麻烦提issue，不要评论，因为评论不会自动提醒。issue会自动发邮件提醒作者。","routePath":"/start/","lang":"","toc":[{"text":"实话实说","id":"实话实说","depth":2,"charIndex":24},{"text":"什么是AI安全","id":"什么是ai安全","depth":2,"charIndex":131},{"text":"AI安全的类别","id":"ai安全的类别","depth":2,"charIndex":386},{"text":"1.对抗性攻击与防御（Adversarial ML）","id":"1对抗性攻击与防御adversarial-ml","depth":3,"charIndex":397},{"text":"2.**隐私保护（Privacy in AI）**","id":"2隐私保护privacy-in-ai","depth":3,"charIndex":-1},{"text":"3.模型行为安全（Behavioral Safety）","id":"3模型行为安全behavioral-safety","depth":3,"charIndex":452},{"text":"4. **后门与模型篡改防御（Backdoor/Poisoning）**","id":"4-后门与模型篡改防御backdoorpoisoning","depth":3,"charIndex":-1},{"text":"5. **大模型（LLM）安全**","id":"5-大模型llm安全","depth":3,"charIndex":-1},{"text":"","id":"","depth":2,"charIndex":551}],"domain":"","frontmatter":{},"version":""}]